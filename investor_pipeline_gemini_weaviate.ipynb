{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa374e7",
   "metadata": {},
   "source": [
    "\n",
    "# Investor Ownership & News Pipeline (Gemini + Fintel + Yahoo + Weaviate + RDF)\n",
    "\n",
    "This notebook implements an end-to-end pipeline to extract investor–company ownership relationships and supporting articles, normalize majority/minority semantics, serialize to RDF, and ingest into Weaviate for Graph-RAG.\n",
    "\n",
    "**Features**\n",
    "- spaCy NER to extract target **Company (ORG)** from user query\n",
    "- **Gemini** search for recent articles with **URLs** (stored as `source_url`)\n",
    "- **Fintel** extraction via **cloudscraper** + **markdownify** with **13D/G** priority; falls back to **13F**\n",
    "- **Yahoo Finance** institutional holders (with `source_url`)\n",
    "- Alias normalization → `majority` if `percentage >= 50` else `minority`\n",
    "- In-memory **RDF** graph for KG\n",
    "- **Weaviate** single-class schema with `source_url` and `investmentDate` and ingestion helpers\n",
    "\n",
    "> Notes:  \n",
    "> - Set your Gemini API key in the environment variable `GEMINI_API_KEY`.  \n",
    "> - Set your Weaviate endpoint in `WEAVIATE_URL`.  \n",
    "> - This notebook includes graceful fallbacks so it can run without external access for demos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional installs (uncomment if needed)\n",
    "# %pip install google-generativeai spacy yfinance cloudscraper markdownify rdflib weaviate-client fastapi uvicorn nbformat\n",
    "# %pip install git+https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl\n",
    "# or: python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba81fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, uuid, json, datetime, math\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# --- LLM / NLP ---\n",
    "import spacy\n",
    "\n",
    "# --- Web / scraping ---\n",
    "import requests\n",
    "import cloudscraper\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "# --- Finance data ---\n",
    "import yfinance as yf\n",
    "\n",
    "# --- KG / RDF ---\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, XSD\n",
    "\n",
    "# --- Weaviate ---\n",
    "try:\n",
    "    import weaviate\n",
    "    WEAVIATE_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(\"Weaviate client not available:\", e)\n",
    "    WEAVIATE_AVAILABLE = False\n",
    "\n",
    "# --- Gemini ---\n",
    "GEMINI_OK = False\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    if os.getenv(\"GEMINI_API_KEY\"):\n",
    "        genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "        GEMINI_OK = True\n",
    "except Exception as e:\n",
    "    print(\"Gemini SDK not available or not configured:\", e)\n",
    "    GEMINI_OK = False\n",
    "\n",
    "# --- spaCy model ---\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except Exception:\n",
    "    try:\n",
    "        from spacy.cli import download\n",
    "        download(\"en_core_web_sm\")\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except Exception as e:\n",
    "        print(\"spaCy model load failed; using blank English model as fallback:\", e)\n",
    "        nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c070369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RELATIONSHIP_SYNONYMS = {\n",
    "    \"majority\": [\n",
    "        \"principle stakeholder\", \"principal stakeholder\", \"major stakeholder\",\n",
    "        \"majority stakeholder\", \"voting control\", \"voting majority\",\n",
    "        \"buyout\", \"acquisition\", \"acquired\", \"controlling interest\", \"equity control\"\n",
    "    ],\n",
    "    \"minority\": [\n",
    "        \"equity stake\", \"invest along with\", \"small shareholding\",\n",
    "        \"minority interest\", \"limited influence\", \"passive investment as minority\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "ALL_SYNONYMS = [s.lower() for lst in RELATIONSHIP_SYNONYMS.values() for s in lst]\n",
    "\n",
    "def detect_relationship_synonyms(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    text_l = text.lower()\n",
    "    found = []\n",
    "    for syn in ALL_SYNONYMS:\n",
    "        if syn in text_l:\n",
    "            found.append(syn)\n",
    "    seen = set(); out = []\n",
    "    for s in found:\n",
    "        if s not in seen:\n",
    "            out.append(s); seen.add(s)\n",
    "    return out\n",
    "\n",
    "def normalize_tag(synonyms: List[str], percentage: Optional[float] = None) -> str:\n",
    "    if percentage is not None and not (isinstance(percentage, (int, float)) and not math.isnan(float(percentage))):\n",
    "        percentage = None\n",
    "    if percentage is not None:\n",
    "        return \"majority\" if float(percentage) >= 50.0 else \"minority\"\n",
    "    for syn in synonyms:\n",
    "        for tag, tag_syns in RELATIONSHIP_SYNONYMS.items():\n",
    "            if syn in [s.lower() for s in tag_syns]:\n",
    "                return tag\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a543191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COMPANY_TICKER_MAP = {\n",
    "    \"BlackRock\": \"BLK\",\n",
    "    \"Apple\": \"AAPL\",\n",
    "    \"Microsoft\": \"MSFT\",\n",
    "    \"Tesla\": \"TSLA\",\n",
    "    \"Amazon\": \"AMZN\",\n",
    "    \"Dropbox\": \"DBX\",\n",
    "    \"Company B\": \"B\",\n",
    "}\n",
    "\n",
    "def extract_target_company(query: str) -> str:\n",
    "    doc = nlp(query)\n",
    "    for ent in getattr(doc, \"ents\", []):\n",
    "        if getattr(ent, \"label_\", None) == \"ORG\":\n",
    "            return ent.text\n",
    "    m = re.search(r\"[A-Z][\\w&.,()\\- ]{2,}\", query)\n",
    "    return m.group(0).strip() if m else \"Company B\"\n",
    "\n",
    "def get_ticker(company_name: str) -> Optional[str]:\n",
    "    ticker = COMPANY_TICKER_MAP.get(company_name.strip())\n",
    "    if ticker:\n",
    "        return ticker\n",
    "    if company_name.isupper() and 1 <= len(company_name) <= 5:\n",
    "        return company_name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gemini_search_news(query: str, max_items: int = 5) -> List[Dict[str, Any]]:\n",
    "    if not GEMINI_OK:\n",
    "        return [\n",
    "            {\"title\": f\"{query} majority buyout reported\",\"url\": \"https://example.com/article-1\",\"summary\": f\"Report suggests a controlling interest related to {query}.\",\"date\": \"2024-05-15\"},\n",
    "            {\"title\": f\"{query} minority investments update\",\"url\": \"https://example.com/article-2\",\"summary\": f\"Smaller equity stakes discussed for {query}.\",\"date\": \"2024-02-10\"}\n",
    "        ]\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    prompt = (\n",
    "        \"Search the web and return a STRICT JSON array of objects with keys: \"\n",
    "        \"title, url, summary, date (YYYY-MM-DD). \"\n",
    "        \"Focus on institutional ownership, 13D/13G filings, control/majority, buyouts. \"\n",
    "        f\"Query: {query}\"\n",
    "    )\n",
    "    try:\n",
    "        resp = model.generate_content(prompt)\n",
    "        text = resp.text.strip()\n",
    "        data = None\n",
    "        try:\n",
    "            data = json.loads(text)\n",
    "            if isinstance(data, dict) and 'results' in data:\n",
    "                data = data['results']\n",
    "        except Exception:\n",
    "            import re as _re\n",
    "            m = _re.search(r\"\\[\\s*{[\\s\\S]*?}\\s*\\]\", text)\n",
    "            if m:\n",
    "                data = json.loads(m.group(0))\n",
    "        if not data or not isinstance(data, list):\n",
    "            raise ValueError(\"Non-JSON or empty response\")\n",
    "        out = []\n",
    "        for item in data[:max_items]:\n",
    "            out.append({\n",
    "                \"title\": str(item.get(\"title\",\"\")).strip(),\n",
    "                \"url\": str(item.get(\"url\",\"\")).strip(),\n",
    "                \"summary\": str(item.get(\"summary\",\"\")).strip(),\n",
    "                \"date\": str(item.get(\"date\",\"\")).strip() or None\n",
    "            })\n",
    "        return [x for x in out if x.get(\"url\")]\n",
    "    except Exception as e:\n",
    "        return [{\"title\": f\"{query} majority buyout reported\",\"url\": \"https://example.com/article-1\",\"summary\": f\"Report suggests a controlling interest related to {query}.\",\"date\": \"2024-05-15\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eebb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _extract_markdown_tables(markdown_text: str) -> List[List[str]]:\n",
    "    lines = markdown_text.splitlines()\n",
    "    tables = []\n",
    "    current = []\n",
    "    for line in lines:\n",
    "        if \"|\" in line:\n",
    "            current.append(line)\n",
    "        elif current:\n",
    "            if any('---' in ln for ln in current[:3]):\n",
    "                tables.append(current)\n",
    "            current = []\n",
    "    if current and any('---' in ln for ln in current[:3]):\n",
    "        tables.append(current)\n",
    "    return tables\n",
    "\n",
    "def _parse_md_table(table_lines: List[str]) -> List[Dict[str, str]]:\n",
    "    if not table_lines: return []\n",
    "    header = [h.strip() for h in table_lines[0].split(\"|\") if h.strip()]\n",
    "    rows = []\n",
    "    for row_line in table_lines[2:]:\n",
    "        cols = [c.strip() for c in row_line.split(\"|\") if c.strip()]\n",
    "        if len(cols) != len(header):\n",
    "            continue\n",
    "        rows.append(dict(zip(header, cols)))\n",
    "    return rows\n",
    "\n",
    "def fetch_fintel_ownership(ticker: str) -> List[Dict[str, Any]]:\n",
    "    url = f\"https://fintel.io/so/us/{ticker.lower()}\"\n",
    "    try:\n",
    "        scraper = cloudscraper.create_scraper(browser={\n",
    "            'browser': 'chrome',\n",
    "            'platform': 'windows',\n",
    "            'mobile': False\n",
    "        })\n",
    "        html = scraper.get(url).text\n",
    "        markdown_text = md(html)\n",
    "        tables = _extract_markdown_tables(markdown_text)\n",
    "\n",
    "        chosen_rows: List[Dict[str,str]] = []\n",
    "        for tbl in tables:\n",
    "            rows = _parse_md_table(tbl)\n",
    "            if rows:\n",
    "                keys = [k.lower() for k in rows[0].keys()]\n",
    "                if any((\"13d\" in k) or (\"13g\" in k) or (\"schedule\" in k) or (\"file\" in k and \"date\" in k) for k in keys):\n",
    "                    chosen_rows = rows\n",
    "                    break\n",
    "        if not chosen_rows and tables:\n",
    "            chosen_rows = _parse_md_table(tables[0])\n",
    "        if not chosen_rows:\n",
    "            return []\n",
    "\n",
    "        results = []\n",
    "        for row in chosen_rows:\n",
    "            investor = (\n",
    "                row.get(\"Investor\") or row.get(\"Holder\") or row.get(\"Filer\") or\n",
    "                row.get(\"Institution\") or next(iter(row.values()), None)\n",
    "            )\n",
    "            pct_text = (\n",
    "                row.get(\"% Ownership\") or row.get(\"% Out\") or row.get(\"Ownership (%)\") or\n",
    "                row.get(\"% O/S\") or row.get(\"Percent\") or \"\"\n",
    "            )\n",
    "            date = (\n",
    "                row.get(\"Effective Date\") or row.get(\"File Date\") or\n",
    "                row.get(\"Filing Date\") or row.get(\"Reported Date\") or None\n",
    "            )\n",
    "            pct_val = None\n",
    "            if pct_text:\n",
    "                try:\n",
    "                    pct_val = float(pct_text.replace(\"%\", \"\").replace(\",\",\"\").strip())\n",
    "                except Exception:\n",
    "                    pct_val = None\n",
    "\n",
    "            results.append({\n",
    "                \"investor\": investor,\n",
    "                \"company\": ticker.upper(),\n",
    "                \"percentage\": pct_val,\n",
    "                \"source\": \"Fintel (13D/G preferred; 13F fallback)\",\n",
    "                \"investment_date\": date,\n",
    "                \"source_url\": url,\n",
    "                \"raw_text\": \" | \".join([f\"{k}: {v}\" for k, v in row.items()])\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Fintel fetch error for {ticker}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_yahoo_ownership(ticker: str) -> List[Dict[str, Any]]:\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker.upper()}/holders\"\n",
    "    try:\n",
    "        t = yf.Ticker(ticker.upper())\n",
    "        df = t.institutional_holders\n",
    "        if df is None or df.empty:\n",
    "            return []\n",
    "        results = []\n",
    "        for _, row in df.iterrows():\n",
    "            investor = row.get(\"Holder\")\n",
    "            pct = row.get(\"% Out\")\n",
    "            pct_val = None\n",
    "            if pct is not None:\n",
    "                try:\n",
    "                    pct_val = float(str(pct).replace(\"%\",\"\").replace(\",\",\"\").strip())\n",
    "                except Exception:\n",
    "                    pct_val = None\n",
    "            results.append({\n",
    "                \"investor\": investor,\n",
    "                \"company\": ticker.upper(),\n",
    "                \"percentage\": pct_val,\n",
    "                \"source\": \"Yahoo Finance (Institutional Holders)\",\n",
    "                \"investment_date\": None,\n",
    "                \"source_url\": url,\n",
    "                \"raw_text\": f\"{investor} | %Out: {pct}\"\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Yahoo ownership fetch error for {ticker}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_events(events: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    by_key: Dict[Tuple[str,str], Dict[str, Any]] = {}\n",
    "    for e in events:\n",
    "        if not e.get(\"investor\"):\n",
    "            continue\n",
    "        key = (e[\"investor\"].strip().lower(), e[\"company\"].strip().lower())\n",
    "        if key not in by_key:\n",
    "            by_key[key] = dict(e)\n",
    "            by_key[key][\"source_url\"] = [e.get(\"source_url\")] if e.get(\"source_url\") else []\n",
    "        else:\n",
    "            p_existing = by_key[key].get(\"percentage\")\n",
    "            p_new = e.get(\"percentage\")\n",
    "            if p_new is not None and (p_existing is None or p_new > p_existing):\n",
    "                by_key[key][\"percentage\"] = p_new\n",
    "            by_key[key][\"raw_text\"] = (by_key[key].get(\"raw_text\",\"\") + \" || \" + e.get(\"raw_text\",\"\")).strip(\" |\")\n",
    "            if e.get(\"source_url\"):\n",
    "                by_key[key][\"source_url\"].append(e[\"source_url\"])\n",
    "        if not by_key[key].get(\"investment_date\") and e.get(\"investment_date\"):\n",
    "            by_key[key][\"investment_date\"] = e[\"investment_date\"]\n",
    "        if e.get(\"source\") and \"Yahoo\" in e[\"source\"]:\n",
    "            by_key[key][\"source\"] = e[\"source\"]\n",
    "        elif e.get(\"source\") and \"Fintel\" in e[\"source\"]:\n",
    "            by_key[key][\"source\"] = e[\"source\"]\n",
    "    out = []\n",
    "    for e in by_key.values():\n",
    "        syns = detect_relationship_synonyms(e.get(\"raw_text\",\"\"))\n",
    "        tag = normalize_tag(syns, e.get(\"percentage\"))\n",
    "        e[\"relationship_tag\"] = tag\n",
    "        e[\"relationship_synonyms\"] = syns\n",
    "        urls = [u for u in (e.get(\"source_url\") or []) if u]\n",
    "        e[\"source_url\"] = sorted(set(urls))\n",
    "        out.append(e)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479858da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EX = Namespace(\"http://example.com/onto/\")\n",
    "EXR = Namespace(\"http://example.com/resource/\")\n",
    "\n",
    "def event_to_rdf(event: Dict[str, Any]) -> Graph:\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX); g.bind(\"exr\", EXR)\n",
    "    inv = (event.get(\"investor\") or \"unknown-investor\").lower()\n",
    "    co = (event.get(\"company\") or \"unknown-company\").lower()\n",
    "    actor_uri = URIRef(EXR + re.sub(r'\\\\W+','-', inv))\n",
    "    target_uri = URIRef(EXR + re.sub(r'\\\\W+','-', co))\n",
    "    rel_uri = URIRef(EXR + f\"OwnershipRelationship-{uuid.uuid4().hex[:8]}\")\n",
    "    g.add((actor_uri, RDF.type, EX.Investor))\n",
    "    g.add((target_uri, RDF.type, EX.Company))\n",
    "    g.add((rel_uri, RDF.type, EX.OwnershipRelationship))\n",
    "    g.add((rel_uri, EX.investor, actor_uri))\n",
    "    g.add((rel_uri, EX.company, target_uri))\n",
    "    pct = event.get(\"percentage\")\n",
    "    if pct is not None:\n",
    "        try:\n",
    "            g.add((rel_uri, EX.percentage, Literal(float(pct), datatype=XSD.decimal)))\n",
    "        except Exception:\n",
    "            pass\n",
    "    g.add((rel_uri, EX.relationshipTag, Literal(event.get(\"relationship_tag\",\"unknown\"))))\n",
    "    for syn in event.get(\"relationship_synonyms\", []):\n",
    "        g.add((rel_uri, EX.relationshipSynonym, Literal(syn)))\n",
    "    for u in event.get(\"source_url\", []):\n",
    "        try:\n",
    "            g.add((rel_uri, EX.sourceURL, URIRef(u)))\n",
    "        except Exception:\n",
    "            g.add((rel_uri, EX.sourceURL, Literal(u)))\n",
    "    if event.get(\"investment_date\"):\n",
    "        try:\n",
    "            g.add((rel_uri, EX.investmentDate, Literal(event[\"investment_date\"], datatype=XSD.date)))\n",
    "        except Exception:\n",
    "            g.add((rel_uri, EX.investmentDate, Literal(event[\"investment_date\"])))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f542fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\", \"http://localhost:8080\")\n",
    "\n",
    "def ensure_weaviate_schema():\n",
    "    if not WEAVIATE_AVAILABLE:\n",
    "        print(\"Weaviate client not installed; skipping schema setup.\")\n",
    "        return\n",
    "    client = weaviate.Client(WEAVIATE_URL)\n",
    "    class_name = \"OwnershipRelation\"\n",
    "    schema_def = {\n",
    "        \"class\": class_name,\n",
    "        \"description\": \"Investor->Company ownership/investment relation\",\n",
    "        \"vectorizer\": \"none\",\n",
    "        \"properties\": [\n",
    "            {\"name\":\"investor\", \"dataType\":[\"text\"], \"description\":\"Investor entity\"},\n",
    "            {\"name\":\"company\", \"dataType\":[\"text\"], \"description\":\"Target company\"},\n",
    "            {\"name\":\"percentage\", \"dataType\":[\"number\"], \"description\":\"Ownership %\"},\n",
    "            {\"name\":\"relationshipType\", \"dataType\":[\"text\"], \"description\":\"majority/minority/unknown\"},\n",
    "            {\"name\":\"investmentDate\", \"dataType\":[\"date\"], \"description\":\"Date from filing/news\"},\n",
    "            {\"name\":\"source\", \"dataType\":[\"text\"], \"description\":\"Source descriptor (Fintel/Yahoo/News)\"},\n",
    "            {\"name\":\"source_url\", \"dataType\":[\"text[]\"], \"description\":\"URLs used to derive this record\"},\n",
    "            {\"name\":\"raw_text\", \"dataType\":[\"text\"], \"description\":\"Raw extracted text blob\"}\n",
    "        ]\n",
    "    }\n",
    "    schema = client.schema.get()\n",
    "    existing = [c[\"class\"] for c in schema.get(\"classes\", [])]\n",
    "    if class_name in existing:\n",
    "        client.schema.delete_class(class_name)\n",
    "    client.schema.create_class(schema_def)\n",
    "    print(\"✅ Weaviate schema ensured for class:\", class_name)\n",
    "\n",
    "def weaviate_upsert_events(events: List[Dict[str, Any]]):\n",
    "    if not WEAVIATE_AVAILABLE:\n",
    "        print(\"Weaviate client not installed; skipping ingestion.\")\n",
    "        return\n",
    "    client = weaviate.Client(WEAVIATE_URL)\n",
    "    batch = client.batch\n",
    "    batch.configure(batch_size=50)\n",
    "    with batch as b:\n",
    "        for e in events:\n",
    "            props = {\n",
    "                \"investor\": e.get(\"investor\"),\n",
    "                \"company\": e.get(\"company\"),\n",
    "                \"percentage\": e.get(\"percentage\"),\n",
    "                \"relationshipType\": e.get(\"relationship_tag\"),\n",
    "                \"investmentDate\": e.get(\"investment_date\"),\n",
    "                \"source\": e.get(\"source\"),\n",
    "                \"source_url\": e.get(\"source_url\"),\n",
    "                \"raw_text\": e.get(\"raw_text\")\n",
    "            }\n",
    "            b.add_data_object(props, class_name=\"OwnershipRelation\")\n",
    "    print(f\"✅ Ingested {len(events)} events into Weaviate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_pipeline(query: str) -> Dict[str, Any]:\n",
    "    company = extract_target_company(query)\n",
    "    ticker = get_ticker(company) or company\n",
    "    yahoo = fetch_yahoo_ownership(ticker)\n",
    "    fintel = fetch_fintel_ownership(ticker)\n",
    "    news = gemini_search_news(f\"{company} institutional ownership OR 13D OR 13G OR controlling interest\")\n",
    "    news_events = []\n",
    "    for n in news:\n",
    "        news_events.append({\n",
    "            \"investor\": None,\n",
    "            \"company\": str(ticker).upper(),\n",
    "            \"percentage\": None,\n",
    "            \"source\": \"Gemini (news)\",\n",
    "            \"investment_date\": n.get(\"date\"),\n",
    "            \"source_url\": n.get(\"url\"),\n",
    "            \"raw_text\": f\"{n.get('title','')} :: {n.get('summary','')}\"\n",
    "        })\n",
    "    merged = merge_events(yahoo + fintel)\n",
    "    g_all = Graph(); g_all.bind(\"ex\",\"http://example.com/onto/\"); g_all.bind(\"exr\",\"http://example.com/resource/\")\n",
    "    for e in merged:\n",
    "        news_urls = [n[\"url\"] for n in news]\n",
    "        e[\"source_url\"] = sorted(set((e.get(\"source_url\") or []) + news_urls))\n",
    "        g_all += event_to_rdf(e)\n",
    "    rdf_turtle = g_all.serialize(format=\"turtle\")\n",
    "    if hasattr(rdf_turtle, \"decode\"):\n",
    "        rdf_turtle = rdf_turtle.decode(\"utf-8\")\n",
    "    ensure_weaviate_schema()\n",
    "    weaviate_upsert_events(merged)\n",
    "    maj = [e for e in merged if e.get(\"relationship_tag\") == \"majority\"]\n",
    "    mino = [e for e in merged if e.get(\"relationship_tag\") == \"minority\"]\n",
    "    summary = {\n",
    "        \"company\": company,\n",
    "        \"ticker\": ticker,\n",
    "        \"counts\": {\"majority\": len(maj), \"minority\": len(mino), \"total\": len(merged)},\n",
    "        \"note\": \"Percentages >= 50 are tagged as 'majority'; otherwise 'minority'.\"\n",
    "    }\n",
    "    return {\n",
    "        \"company\": company,\n",
    "        \"ticker\": ticker,\n",
    "        \"events\": merged,\n",
    "        \"news\": news,\n",
    "        \"rdf_turtle\": rdf_turtle,\n",
    "        \"summary\": summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DEMO ---\n",
    "result = run_pipeline(\"Who are the largest institutional holders of Dropbox?\")\n",
    "print(json.dumps(result[\"summary\"], indent=2))\n",
    "print(\"\\nTop 3 events (preview):\")\n",
    "for e in result[\"events\"][:3]:\n",
    "    print(json.dumps(e, indent=2))\n",
    "print(\"\\nRDF Turtle (first 600 chars):\\n\", result[\"rdf_turtle\"][:600], \"...\")\n",
    "print(\"\\nNews items (preview):\")\n",
    "for n in result[\"news\"][:3]:\n",
    "    print(\"-\", n.get(\"title\"), n.get(\"url\"))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
