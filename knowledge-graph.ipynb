# ============================================
# Investor Relationship Extraction & KG Notebook
# ============================================

# -------------------------
# 1. Setup & Imports
# -------------------------
import re, uuid, json
from typing import List, Dict, Any, Optional
from rdflib import Graph, Namespace, URIRef, Literal
from rdflib.namespace import RDF, XSD
from dateutil import parser as dparser
from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
from bs4 import BeautifulSoup

# For mock web search
import random

# -------------------------
# 2. Alias Mapping & Normalization
# -------------------------
RELATIONSHIP_SYNONYMS = {
    "majority": ["Principle stakeholder", "Principal stakeholder", "Major stakeholder",
                 "majority stakeholder", "voting control", "voting majority",
                 "buyout", "Acquisition", "Acquired", "controlling interest", "equity control"],
    "minority": ["Equity stake","Invest along with","Small shareholding","minority interest",
                 "limited influence","passive investment as minority"]
}

# Flatten synonyms for matching
ALL_SYNONYMS = [s.lower() for lst in RELATIONSHIP_SYNONYMS.values() for s in lst]

def detect_relationship_synonyms(text: str) -> List[str]:
    """Return all synonyms found in text (case-insensitive)."""
    found = []
    text_l = text.lower()
    for syn in ALL_SYNONYMS:
        if syn in text_l:
            found.append(syn)
    return list(set(found))  # unique

def normalize_tag(synonyms: List[str], percentage: Optional[float] = None) -> str:
    """Determine normalized tag based on synonyms + percentage."""
    for syn in synonyms:
        for tag, tag_syns in RELATIONSHIP_SYNONYMS.items():
            if syn in [s.lower() for s in tag_syns]:
                if percentage is not None:
                    return "majority" if percentage >= 50 else "minority"
                return tag
    if percentage is not None:
        return "majority" if percentage >= 50 else "minority"
    return "unknown"

# -------------------------
# 3. Mock Web Search & Scraper
# -------------------------
def mock_web_search(query: str, max_results: int = 2) -> List[Dict[str,str]]:
    """Simulate search results from Google, Yahoo Finance, Fintel"""
    results = []
    sources = ["Google", "Yahoo Finance", "Fintel"]
    sample_texts = [
        f"{query} shows that BlackRock completed a majority buyout of Company B acquiring 55%.",
        f"{query} indicates Investor A invested $50M alongside Investor B in a Series B.",
        f"{query} reports Company Z owns a small shareholding in Company Y.",
    ]
    for src in sources:
        for i in range(max_results):
            text = random.choice(sample_texts)
            results.append({
                "title": f"{src} Result {i+1} for {query}",
                "url": f"https://{src.lower().replace(' ','')}.com/sample-{i+1}",
                "text": text
            })
    return results

def extract_text_from_html(html_content: str) -> str:
    """Extract main text from HTML page"""
    soup = BeautifulSoup(html_content, "html.parser")
    paragraphs = soup.find_all("p")
    text = " ".join([p.get_text() for p in paragraphs])
    return text or html_content

# -------------------------
# 4. Mock LLM Extraction
# -------------------------
def mock_llm_extract(article_text: str, source_url: Optional[str]=None) -> Dict[str,Any]:
    """Mock LLM extraction for investor/target/percentage/synonyms"""
    # Detect explicit percentage
    m_pct = re.search(r'(\d{1,3}(?:\.\d+)?)\s*%', article_text)
    percentage = float(m_pct.group(1)) if m_pct else None

    # Detect investor and target heuristically
    # Find two capitalized phrases as actor/target
    caps = re.findall(r'([A-Z][\w&\.-]+(?:\s+[A-Z][\w&\.-]+)*)', article_text)
    actor = caps[0] if len(caps) > 0 else None
    target = caps[1] if len(caps) > 1 else None

    # Detect synonyms
    synonyms = detect_relationship_synonyms(article_text)
    tag = normalize_tag(synonyms, percentage)

    # Build JSON event
    json_event = {
        "event_type": "ownership" if percentage or any(k in article_text.lower() for k in ["buyout","acquired"]) else "investment",
        "actor": {"name": actor, "type": "investor"},
        "target": {"name": target, "type": "company"},
        "percentage": percentage,
        "relationship_tag": tag,
        "relationship_synonyms": synonyms,
        "amount": None,
        "currency": None,
        "round": None,
        "effective_date": None,
        "announcement_date": None,
        "source_url": source_url,
        "confidence": 0.8,
        "raw_text": article_text
    }
    return json_event

# -------------------------
# 5. RDF Generation
# -------------------------
EX = Namespace("http://example.com/onto/")
EXR = Namespace("http://example.com/resource/")

def json_to_rdf(event: Dict[str,Any]) -> Graph:
    g = Graph()
    g.bind("ex", EX)
    g.bind("exr", EXR)
    actor_uri = URIRef(EXR + re.sub(r'\W+','-', (event['actor']['name'] or 'unknown').lower()))
    target_uri = URIRef(EXR + re.sub(r'\W+','-', (event['target']['name'] or 'unknown').lower()))
    g.add((actor_uri, RDF.type, EX.Investor))
    g.add((target_uri, RDF.type, EX.Company))
    event_uri = URIRef(EXR + f"{event['event_type']}_{uuid.uuid4().hex[:6]}")
    g.add((event_uri, RDF.type, EX.OwnershipEvent))
    g.add((event_uri, EX.hasInvestor, actor_uri))
    g.add((event_uri, EX.hasOwnedEntity, target_uri))
    if event['percentage'] is not None:
        g.add((event_uri, EX.percentage, Literal(float(event['percentage']), datatype=XSD.decimal)))
    g.add((event_uri, EX.relationshipTag, Literal(event['relationship_tag'])))
    for syn in event['relationship_synonyms']:
        g.add((event_uri, EX.relationshipSynonym, Literal(syn)))
    if event['source_url']:
        g.add((event_uri, EX.source_url, URIRef(event['source_url'])))
    # Add ownership/control shortcut
    if event['percentage'] and event['percentage'] >= 50:
        g.add((actor_uri, EX.controls, target_uri))
    else:
        g.add((actor_uri, EX.owns, target_uri))
    return g

# -------------------------
# 6. Weaviate Payload
# -------------------------
def build_weaviate_object(event: Dict[str,Any], kg_ids: List[str], kg_triples: List[str]) -> Dict[str,Any]:
    obj = {
        "class": "InvestorRelationship",
        "properties": {
            "investor": event['actor']['name'],
            "company": event['target']['name'],
            "raw_text": event['raw_text'],
            "relationship_tag": event['relationship_tag'],
            "relationship_synonyms": event['relationship_synonyms'],
            "percentage_estimate": event['percentage'],
            "source_url": event['source_url']
        },
        "kg_ids": kg_ids,
        "kg_triples": kg_triples
    }
    return obj

# -------------------------
# 7. Batch Pipeline
# -------------------------
def process_articles(query: str) -> Dict[str,Any]:
    # Step 1: Mock web search
    articles = mock_web_search(query)

    merged_graph = Graph()
    merged_graph.bind("ex", EX)
    merged_graph.bind("exr", EXR)
    all_weaviate_objects = []
    all_json_events = []

    for art in articles:
        json_event = mock_llm_extract(art['text'], source_url=art['url'])
        rdf_graph = json_to_rdf(json_event)
        merged_graph += rdf_graph
        kg_ids = [str(s) for s in rdf_graph.subjects()]
        triples = [str(t) for t in rdf_graph]
        weaviate_obj = build_weaviate_object(json_event, kg_ids, triples)
        all_weaviate_objects.append(weaviate_obj)
        all_json_events.append(json_event)

    return {
        "json_events": all_json_events,
        "rdf_turtle": merged_graph.serialize(format="turtle"),
        "weaviate_objects": all_weaviate_objects
    }

# -------------------------
# 8. Mock LLM Summary
# -------------------------
def summarize_investor_data(json_events: List[Dict[str,Any]]) -> str:
    summary = []
    for evt in json_events:
        pct_str = f"{evt['percentage']}%" if evt['percentage'] else "unknown %"
        summary.append(f"{evt['actor']['name']} {evt['relationship_tag']} owns {pct_str} of {evt['target']['name']}")
    return "\n".join(summary)

# -------------------------
# 9. FastAPI Endpoint
# -------------------------
app = FastAPI()

class QueryRequest(BaseModel):
    query: str

@app.post("/extract_and_summarize")
def extract_and_summarize(req: QueryRequest):
    pipeline_output = process_articles(req.query)
    summary = summarize_investor_data(pipeline_output['json_events'])
    return {
        "json_events": pipeline_output['json_events'],
        "rdf_turtle": pipeline_output['rdf_turtle'],
        "weaviate_objects": pipeline_output['weaviate_objects'],
        "summary": summary
    }

# -------------------------
# 10. Run FastAPI (if needed)
# -------------------------
# Uncomment below lines to run inside notebook (requires nest_asyncio)
# import nest_asyncio
# nest_asyncio.apply()
# uvicorn.run(app, host="0.0.0.0", port=8000)

# -------------------------
# 11. Test Batch Pipeline
# -------------------------
if __name__ == "__main__":
    query = "BlackRock investments in Company B"
    output = process_articles(query)
    print("=== JSON Events ===")
    print(json.dumps(output['json_events'], indent=2))
    print("\n=== RDF Turtle ===")
    print(output['rdf_turtle'][:500] + "...\n")  # truncated for display
    print("=== Weaviate Objects ===")
    print(json.dumps(output['weaviate_objects'], indent=2))
    print("\n=== Summary ===")
    print(summarize_investor_data(output['json_events']))
